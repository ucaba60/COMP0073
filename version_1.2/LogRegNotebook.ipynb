{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ce9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import string\n",
    "from collections import Counter\n",
    "from statistics import mean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import textstat\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Constants\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "FUNCTION_WORDS = {'a', 'in', 'of', 'the'}\n",
    "\n",
    "\n",
    "def remove_prefix(data):\n",
    "    \"\"\"\n",
    "    This function removes a predefined prefix from each text in a given dataset.\n",
    "\n",
    "    Args:\n",
    "    data (list of tuples): The data from the dataset. Each element of the list is a tuple, where the first element\n",
    "    is the text and the second element is its label.\n",
    "\n",
    "    Returns:\n",
    "    texts (list): The list of texts after the prefix has been removed.\n",
    "    labels (list): The list of labels corresponding to the texts.\n",
    "    \"\"\"\n",
    "\n",
    "    texts, labels = zip(*data)\n",
    "\n",
    "    prefixes = [\"Answer:\", \"Story:\", \"Article:\"]\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        texts = [text.split(prefix, 1)[1].strip() if prefix in text else text for text in texts]\n",
    "\n",
    "    return list(texts), list(labels)\n",
    "\n",
    "\n",
    "def count_pos_tags_and_special_elements(text):\n",
    "    \"\"\"\n",
    "      This function counts the frequency of POS (Part of Speech) tags, punctuation marks, and function words in a given text.\n",
    "      It uses the SpaCy library for POS tagging.\n",
    "\n",
    "      Args:\n",
    "      text (str): The text for which to count POS tags and special elements.\n",
    "\n",
    "      Returns:\n",
    "      pos_counts (dict): A dictionary where keys are POS tags and values are their corresponding count.\n",
    "      punctuation_counts (dict): A dictionary where keys are punctuation marks and values are their corresponding count.\n",
    "      function_word_counts (dict): A dictionary where keys are function words and values are their corresponding count.\n",
    "\n",
    "    \"\"\"\n",
    "    # Use SpaCy to parse the text\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Create a counter of POS tags\n",
    "    pos_counts = Counter(token.pos_ for token in doc)\n",
    "\n",
    "    # Create a counter of punctuation marks\n",
    "    punctuation_counts = Counter(token.text for token in doc if token.pos_ == 'PUNCT')\n",
    "\n",
    "    # Create a counter of function words\n",
    "    function_word_counts = Counter(token.text for token in doc if token.lower_ in FUNCTION_WORDS)\n",
    "\n",
    "    return dict(pos_counts), dict(punctuation_counts), dict(function_word_counts)\n",
    "\n",
    "\n",
    "def load_and_count(dataset_name, data):\n",
    "    \"\"\"\n",
    "       This function loads the texts from the dataset and calculates the frequency of POS tags, punctuation marks,\n",
    "       and function words.\n",
    "\n",
    "       Args:\n",
    "       dataset_name (str): The name of the dataset.\n",
    "       data (list of tuples): The data from the dataset. Each element of the list is a tuple, where the first element\n",
    "       is the text and the second element is its label.\n",
    "\n",
    "       Returns:\n",
    "       overall_pos_counts (Counter): A Counter object of POS tag frequencies.\n",
    "       overall_punctuation_counts (Counter): A Counter object of punctuation mark frequencies.\n",
    "       overall_function_word_counts (Counter): A Counter object of function word frequencies.\n",
    "    \"\"\"\n",
    "\n",
    "    # CHECKED\n",
    "    # Extract texts\n",
    "    texts, labels = remove_prefix(dataset_name)\n",
    "\n",
    "    # Calculate POS tag frequencies for the texts\n",
    "    pos_frequencies, punctuation_frequencies, function_word_frequencies = zip(\n",
    "        *[count_pos_tags_and_special_elements(text) for text in texts])\n",
    "\n",
    "    # Then, sum the dictionaries to get the overall frequencies\n",
    "    overall_pos_counts = Counter()\n",
    "    for pos_freq in pos_frequencies:\n",
    "        overall_pos_counts += Counter(pos_freq)\n",
    "\n",
    "    overall_punctuation_counts = Counter()\n",
    "    for punct_freq in punctuation_frequencies:\n",
    "        overall_punctuation_counts += Counter(punct_freq)\n",
    "\n",
    "    overall_function_word_counts = Counter()\n",
    "    for function_word_freq in function_word_frequencies:\n",
    "        overall_function_word_counts += Counter(function_word_freq)\n",
    "\n",
    "    return overall_pos_counts, overall_punctuation_counts, overall_function_word_counts\n",
    "\n",
    "\n",
    "def calculate_readability_scores(text):\n",
    "    \"\"\"\n",
    "    This function calculates the Flesch Reading Ease and Flesch-Kincaid Grade Level of a text using the textstat library.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to score.\n",
    "\n",
    "    Returns:\n",
    "    flesch_reading_ease (float): The Flesch Reading Ease score of the text.\n",
    "    flesch_kincaid_grade_level (float): The Flesch-Kincaid Grade Level of the text.\n",
    "\n",
    "    \"\"\"\n",
    "    flesch_reading_ease = textstat.flesch_reading_ease(text)\n",
    "    flesch_kincaid_grade_level = textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "    return flesch_reading_ease, flesch_kincaid_grade_level\n",
    "\n",
    "\n",
    "def calculate_average_word_length(texts):\n",
    "    \"\"\"\n",
    "     This function calculates the average word length of a list of texts using the SpaCy library.\n",
    "\n",
    "     Args:\n",
    "     texts (list): The list of texts.\n",
    "\n",
    "     Returns:\n",
    "     (float): The average word length.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    word_lengths = []\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        for token in doc:\n",
    "            if not token.is_punct:  # ignore punctuation\n",
    "                word_lengths.append(len(token.text))\n",
    "\n",
    "    return mean(word_lengths)\n",
    "\n",
    "\n",
    "def calculate_average_sentence_length(texts):\n",
    "    \"\"\"\n",
    "    This function calculates the average sentence length of a list of texts using the SpaCy library.\n",
    "\n",
    "    Args:\n",
    "    texts (list): The list of texts.\n",
    "\n",
    "    Returns:\n",
    "    avg_sentence_length (float): The average sentence length.\n",
    "    \"\"\"\n",
    "    sentence_lengths = []\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        for sent in doc.sents:\n",
    "            sentence_lengths.append(len(sent))\n",
    "\n",
    "    return mean(sentence_lengths)\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    # CHECKED\n",
    "    \"\"\"\n",
    "      This function loads a pre-trained model and its corresponding tokenizer from the Hugging Face model hub.\n",
    "\n",
    "      Returns:\n",
    "      model: The loaded model.\n",
    "      tokenizer: The tokenizer corresponding to the model.\n",
    "\n",
    "    \"\"\"\n",
    "    # model_name = 'allenai/scibert_scivocab_uncased'\n",
    "    # model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model_name = 'roberta-base'\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    model = RobertaForMaskedLM.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def calculate_perplexity(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Calculates the perplexity of a text using a language model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text for which perplexity will be calculated.\n",
    "    model: The language model used to calculate perplexity.\n",
    "    tokenizer: The tokenizer used to tokenize the text.\n",
    "\n",
    "    Returns:\n",
    "    perplexity (float or None): The calculated perplexity of the text, or None if the text is too long.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "        # Truncate the text to the first 512 tokens\n",
    "        # this step has the extra effect of removing examples with low-quality/garbage content (DetectGPT)\n",
    "        input_ids = input_ids[:, :512]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "            perplexity = torch.exp(loss)\n",
    "        return perplexity.item()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in calculate_perplexity: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(text1, text2, model, tokenizer):\n",
    "    \"\"\"\n",
    "    This function calculates cosine similarity between two texts.\n",
    "\n",
    "    Args:\n",
    "    text1 (str): The first text.\n",
    "    text2 (str): The second text.\n",
    "    model: The language model used to generate word embeddings.\n",
    "    tokenizer: The tokenizer used to tokenize the text.\n",
    "\n",
    "    Returns:\n",
    "    cosine_similarity (float): The cosine similarity between the word embeddings of the two texts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the texts and truncate to the first 512 tokens\n",
    "    input_ids1 = tokenizer.encode(text1, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    input_ids2 = tokenizer.encode(text2, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "    # Generate word embeddings for the texts\n",
    "    embeddings1 = model.roberta(input_ids1)[0].mean(dim=1).squeeze().detach()\n",
    "    embeddings2 = model.roberta(input_ids2)[0].mean(dim=1).squeeze().detach()\n",
    "\n",
    "    # Convert embeddings to numpy arrays\n",
    "    embeddings1_np = embeddings1.numpy()\n",
    "    embeddings2_np = embeddings2.numpy()\n",
    "\n",
    "    # Apply L2 normalization to the embeddings\n",
    "    normalized_embeddings1 = normalize(embeddings1_np.reshape(1, -1)).squeeze()\n",
    "    normalized_embeddings2 = normalize(embeddings2_np.reshape(1, -1)).squeeze()\n",
    "\n",
    "    # Convert back to torch tensors\n",
    "    normalized_embeddings1 = torch.from_numpy(normalized_embeddings1)\n",
    "    normalized_embeddings2 = torch.from_numpy(normalized_embeddings2)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = 1 - cosine(normalized_embeddings1.numpy(), normalized_embeddings2.numpy())\n",
    "\n",
    "    return cosine_similarity\n",
    "\n",
    "\n",
    "def extract_prompts_and_texts(data):\n",
    "    \"\"\"\n",
    "    This function extracts prompts and texts from the data.\n",
    "\n",
    "    Args:\n",
    "    data (list of tuples): The data. Each tuple consists of a text (including prompt) and a label.\n",
    "\n",
    "    Returns:\n",
    "    prompts_and_texts (list of tuples): The list of tuples where each tuple contains a prompt and a text.\n",
    "    \"\"\"\n",
    "\n",
    "    prompts_and_texts = []\n",
    "\n",
    "    full_texts, _ = zip(*data)\n",
    "    texts, labels = remove_prefix(data)\n",
    "\n",
    "    starting_points = [\"Question:\", \"Prompt:\", \"Summary:\"]\n",
    "    end_points = [\"Answer:\", \"Story:\", \"Article:\"]\n",
    "\n",
    "    for full_text, text in zip(full_texts, texts):\n",
    "        full_text = full_text.strip()  # Remove leading/trailing white spaces\n",
    "        text = text.strip()\n",
    "        prompt = None\n",
    "        for start, end in zip(starting_points, end_points):\n",
    "            start = start.strip()\n",
    "            end = end.strip()\n",
    "            if start in full_text and end in full_text:\n",
    "                _, temp_prompt = full_text.split(start, 1)\n",
    "                if end in temp_prompt:  # Check if end is present in temp_prompt before splitting\n",
    "                    prompt, _ = temp_prompt.split(end, 1)\n",
    "                    prompt = prompt.strip()\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"WARNING: Unable to find the end string '{end}' in temp_prompt for full text: {full_text} and text: {text}\")\n",
    "                break\n",
    "\n",
    "        if prompt is None:\n",
    "            print(f\"WARNING: No prompt extracted for full text: {full_text} and text: {text}\")\n",
    "            prompt = \"\"  # use an empty string if no prompt is found\n",
    "\n",
    "        prompts_and_texts.append((prompt, text))  # append the prompt and text to the list\n",
    "\n",
    "    return prompts_and_texts\n",
    "\n",
    "\n",
    "def calculate_cosine_similarities_for_dataset(model, tokenizer):\n",
    "    \"\"\"\n",
    "    This function calculates cosine similarities for all (prompt, text) pairs in a dataset.\n",
    "\n",
    "    Args:\n",
    "    model: The language model used to generate word embeddings.\n",
    "    tokenizer: The tokenizer used to tokenize the text.\n",
    "\n",
    "    Returns:\n",
    "    cosine_similarities (list of floats): The list of cosine similarities.\n",
    "    \"\"\"\n",
    "\n",
    "    prompts_and_texts = extract_prompts_and_texts(data)\n",
    "\n",
    "    cosine_similarities = []\n",
    "    for prompt, text in prompts_and_texts:\n",
    "        cosine_similarity = calculate_cosine_similarity(prompt, text, model, tokenizer)\n",
    "        cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "    return cosine_similarities\n",
    "\n",
    "\n",
    "def calculate_cosine_similarities_for_sentences_in_text(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    This function calculates cosine similarities for all consecutive pairs of sentences in a single text.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text for which to calculate cosine similarities.\n",
    "    model: The language model used to generate word embeddings.\n",
    "    tokenizer: The tokenizer used to tokenize the text.\n",
    "\n",
    "    Returns:\n",
    "    cosine_similarities (list of floats): The list of cosine similarities.\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    cosine_similarities = []\n",
    "\n",
    "    for i in range(len(sentences) - 1):\n",
    "        cosine_similarity = calculate_cosine_similarity(sentences[i], sentences[i + 1], model, tokenizer)\n",
    "        cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "    return cosine_similarities\n",
    "\n",
    "\n",
    "def prepare_for_tfidf(text):\n",
    "    \"\"\"\n",
    "    This function pre-processes the text by lowercasing all words, removing punctuation,\n",
    "    removing stop words and lemmatizing the words.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to be pre-processed.\n",
    "\n",
    "    Returns:\n",
    "    text (str): The pre-processed text.\n",
    "    \"\"\"\n",
    "\n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "    # lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "    # join words back into a single string\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def compute_difference_tfidf_words(data_file, n_top_words=10):\n",
    "    \"\"\"\n",
    "    This function reads the input data, focuses only on the texts (responses),\n",
    "    and computes the top n words with the largest average difference in TF-IDF scores\n",
    "    between human-labelled text and AI-generated text.\n",
    "\n",
    "    Args:\n",
    "    data_file (str): The path to the .csv file which contains the texts and labels.\n",
    "    n_top_words (int): The number of top words to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    diff_words (DataFrame): DataFrame with top n words and their average difference in TF-IDF scores.\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv(data_file)\n",
    "    data_tuples = [tuple(x) for x in data.values]\n",
    "    _, texts = zip(*extract_prompts_and_texts(data_tuples))\n",
    "\n",
    "    # preprocess texts\n",
    "    texts = [prepare_for_tfidf(text) for text in texts]\n",
    "\n",
    "    # split data into human and AI generated\n",
    "    human_texts = [text for text, label in zip(texts, data['Label']) if label == 0]\n",
    "    ai_texts = [text for text, label in zip(texts, data['Label']) if label == 1]\n",
    "\n",
    "    # create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # compute TF-IDF for human texts\n",
    "    human_tfidf = vectorizer.fit_transform(human_texts)\n",
    "    feature_names_human = vectorizer.get_feature_names_out()\n",
    "    human_words_tfidf = dict(zip(feature_names_human, human_tfidf.sum(axis=0).tolist()[0]))\n",
    "\n",
    "    # compute TF-IDF for AI texts\n",
    "    ai_tfidf = vectorizer.fit_transform(ai_texts)\n",
    "    feature_names_ai = vectorizer.get_feature_names_out()\n",
    "    ai_words_tfidf = dict(zip(feature_names_ai, ai_tfidf.sum(axis=0).tolist()[0]))\n",
    "\n",
    "    # compute the difference in TF-IDF scores\n",
    "    diff_words_tfidf = {word: human_words_tfidf.get(word, 0) - ai_words_tfidf.get(word, 0)\n",
    "                        for word in set(feature_names_human).union(feature_names_ai)}\n",
    "\n",
    "    diff_words = pd.DataFrame(diff_words_tfidf.items(), columns=['word', 'tfidf_difference']).nlargest(n_top_words,\n",
    "                                                                                                       'tfidf_difference')\n",
    "\n",
    "    return diff_words\n",
    "\n",
    "\n",
    "def plot_diff_tfidf_words(data_file, n_top_words=10):\n",
    "    \"\"\"\n",
    "    This function reads the input data, computes the top n words with the largest average difference in\n",
    "    TF-IDF scores between human-labelled text and AI-generated text, and plots the results.\n",
    "\n",
    "    Args:\n",
    "    data_file (str): The path to the .csv file which contains the texts and labels.\n",
    "    n_top_words (int): The number of top words to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # get the top words with the largest difference in tf-idf\n",
    "    diff_words = compute_difference_tfidf_words(data_file, n_top_words)\n",
    "\n",
    "    # plot the results using seaborn\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    palette = sns.color_palette(\"coolwarm\",\n",
    "                                n_top_words)  # using coolwarm palette, you can use any palette of your liking\n",
    "    sns.barplot(x=diff_words['tfidf_difference'][::-1], y=diff_words['word'][::-1],\n",
    "                palette=palette)  # reverse order to have largest bar at top\n",
    "    plt.xlabel('TF-IDF Difference')\n",
    "    plt.ylabel('Words')\n",
    "    plt.title(\n",
    "        'Top {} Words with Largest Average Difference in TF-IDF Scores between Human and AI-Generated Text'.format(\n",
    "            n_top_words))\n",
    "    plt.show()\n",
    "\n",
    "# plot_diff_tfidf_words(\"extracted_data/gpt-3.5-turbo_and_human_data.csv\")\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity_for_prompt_and_text(prompt, text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    This function calculates cosine similarity for a given (prompt, text) pair.\n",
    "\n",
    "    Args:\n",
    "    prompt (str): The prompt string.\n",
    "    text (str): The text string.\n",
    "    model: The language model used to generate word embeddings.\n",
    "    tokenizer: The tokenizer used to tokenize the text.\n",
    "\n",
    "    Returns:\n",
    "    cosine_similarity (float): The cosine similarity between the prompt and the text.\n",
    "    \"\"\"\n",
    "\n",
    "    cosine_similarity = calculate_cosine_similarity(prompt, text, model, tokenizer)\n",
    "\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40f8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from feature_extraction import remove_prefix, extract_prompts_and_texts\n",
    "from feature_extraction import load_model, count_pos_tags_and_special_elements, calculate_readability_scores, \\\n",
    "    calculate_average_word_length, calculate_average_sentence_length, calculate_perplexity, calculate_cosine_similarity, \\\n",
    "    calculate_cosine_similarities_for_sentences_in_text, calculate_cosine_similarity_for_prompt_and_text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Constants\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "FUNCTION_WORDS = {'a', 'in', 'of', 'the'}\n",
    "\n",
    "\n",
    "def prepare_data_for_regression(data_file, chunk_size=5):\n",
    "    \"\"\"\n",
    "    This function prepares the data for regression analysis by extracting features and labels from the data.\n",
    "\n",
    "    Args:\n",
    "    data_file (str): The path to the full_data.csv file.\n",
    "    save_file (str): The path to the file where the processed data will be saved.\n",
    "    chunk_size (int): The number of rows to process at a time.\n",
    "\n",
    "    Returns:\n",
    "    data_matrix (DataFrame): A DataFrame where each row represents a text, each column represents a feature,\n",
    "                            and the last column is the label.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the model name from the data_file\n",
    "    file_name = data_file.split('/')[-1]  # split the input file string at the slash and take the last part (filename)\n",
    "    model_name = file_name.split('_')[0]  # split the filename at the underscore and take the first part (model name)\n",
    "    save_file = f'data_matrix_{model_name}.csv'  # create save_file name based on the model_name\n",
    "\n",
    "    # Load the model and tokenizer\n",
    "    model, tokenizer = load_model()\n",
    "\n",
    "    # Load saved data if it exists\n",
    "    if os.path.exists(save_file):\n",
    "        saved_data = pd.read_csv(save_file)\n",
    "        processed_rows = len(saved_data)\n",
    "    else:\n",
    "        saved_data = pd.DataFrame()\n",
    "        processed_rows = 0\n",
    "\n",
    "    # Calculate the top 10 words with the highest difference in TF-IDF scores and the vectorizer\n",
    "    #     diff_words = compute_difference_tfidf_words(data_file, n_top_words=10)\n",
    "    top_words = vocabulary = ['said', 'like', 'im', 'get', 'told', 'dont', 'say', 'know', 'think', 'look', 'conclusion',\n",
    "                              'summarise', 'summarize', 'finale', 'overall', 'sum', 'end', 'summary', 'conclude']\n",
    "    # Combine top_words and synonyms into one list\n",
    "    all_words = list(set(top_words))\n",
    "\n",
    "    # Create a TF-IDF vectorizer with the top 10 words as vocabulary\n",
    "    vectorizer = TfidfVectorizer(vocabulary=all_words)\n",
    "\n",
    "    total_rows_processed = 0  # total rows processed in this session\n",
    "\n",
    "    for chunk in pd.read_csv(data_file, chunksize=chunk_size):\n",
    "        feature_list = []\n",
    "\n",
    "        # Skip chunks that have already been processed\n",
    "        if total_rows_processed < processed_rows:\n",
    "            total_rows_processed += len(chunk)\n",
    "            continue\n",
    "\n",
    "        data = list(chunk.itertuples(index=False, name=None))\n",
    "        texts, labels = remove_prefix(data)\n",
    "        prompts_and_texts = extract_prompts_and_texts(data)\n",
    "\n",
    "        for i, ((prompt, text), label) in enumerate(zip(prompts_and_texts, labels)):\n",
    "            try:\n",
    "                features = {}  # Initialize the features dictionary here\n",
    "\n",
    "                # Count POS tags in the text\n",
    "                pos_counts, punctuation_counts, function_word_counts = count_pos_tags_and_special_elements(text)\n",
    "\n",
    "                # Calculate the Flesch Reading Ease and Flesch-Kincaid Grade Level\n",
    "                flesch_reading_ease, flesch_kincaid_grade_level = calculate_readability_scores(text)\n",
    "\n",
    "                # Calculate the average word length\n",
    "                avg_word_length = calculate_average_word_length([text])\n",
    "\n",
    "                # Calculate the average sentence length\n",
    "                avg_sentence_length = calculate_average_sentence_length([text])\n",
    "\n",
    "                # Transform the text into TF-IDF scores\n",
    "                tfidf_scores = vectorizer.fit_transform([text]).toarray()\n",
    "\n",
    "                # Calculate the perplexity of the text and average sentence perplexity\n",
    "                text_encoded = tokenizer.encode(text, truncation=True, max_length=510)\n",
    "                text = tokenizer.decode(text_encoded)\n",
    "                text = text.replace('<s>', '').replace('</s>', '')\n",
    "                text_perplexity = calculate_perplexity(text, model, tokenizer)\n",
    "                sentence_perplexities = [calculate_perplexity(sentence.text, model, tokenizer) for sentence in\n",
    "                                         nlp(text).sents]\n",
    "                sentence_perplexities = [p for p in sentence_perplexities if p is not None]\n",
    "                avg_sentence_perplexity = sum(sentence_perplexities) / len(\n",
    "                    sentence_perplexities) if sentence_perplexities else None\n",
    "\n",
    "                # Calculate the frequency of uppercase letters\n",
    "                uppercase_freq = sum(1 for char in text if char.isupper()) / len(text)\n",
    "\n",
    "                # Calculate the cosine similarity for the prompt and text\n",
    "                prompt_text_cosine_similarity = calculate_cosine_similarity(prompt, text, model, tokenizer)\n",
    "\n",
    "                # Calculate the average cosine similarity for sentences in the text\n",
    "                sentence_cosine_similarities = calculate_cosine_similarities_for_sentences_in_text(text, model,\n",
    "                                                                                                   tokenizer)\n",
    "                avg_sentence_cosine_similarity = None\n",
    "                if sentence_cosine_similarities:\n",
    "                    avg_sentence_cosine_similarity = sum(sentence_cosine_similarities) / len(\n",
    "                        sentence_cosine_similarities)\n",
    "                else:\n",
    "                    print(\"WARNING: No sentence cosine similarities calculated for text:\", text)\n",
    "\n",
    "                # Prepare a dictionary to append to the feature list\n",
    "                features.update({\n",
    "                    'ADJ': pos_counts.get('ADJ', 0),\n",
    "                    'ADV': pos_counts.get('ADV', 0),\n",
    "                    'CONJ': pos_counts.get('CCONJ', 0),\n",
    "                    'NOUN': pos_counts.get('NOUN', 0),\n",
    "                    'NUM': pos_counts.get('NUM', 0),\n",
    "                    'VERB': pos_counts.get('VERB', 0),\n",
    "                    'COMMA': punctuation_counts.get(',', 0),\n",
    "                    'FULLSTOP': punctuation_counts.get('.', 0),\n",
    "                    'SPECIAL-': punctuation_counts.get('-', 0),\n",
    "                    'FUNCTION-A': function_word_counts.get('a', 0),\n",
    "                    'FUNCTION-IN': function_word_counts.get('in', 0),\n",
    "                    'FUNCTION-OF': function_word_counts.get('of', 0),\n",
    "                    'FUNCTION-THE': function_word_counts.get('the', 0),\n",
    "                    'uppercase_freq': uppercase_freq,\n",
    "                    'flesch_reading_ease': flesch_reading_ease,\n",
    "                    'flesch_kincaid_grade_level': flesch_kincaid_grade_level,\n",
    "                    'avg_word_length': avg_word_length,\n",
    "                    'avg_sentence_length': avg_sentence_length,\n",
    "                    'text_perplexity': text_perplexity,\n",
    "                    'avg_sentence_perplexity': avg_sentence_perplexity,\n",
    "                    'prompt_text_cosine_similarity': prompt_text_cosine_similarity,\n",
    "                    'avg_sentence_cosine_similarity': avg_sentence_cosine_similarity,\n",
    "                })\n",
    "\n",
    "                # If the TF-IDF scores array is not empty, zip the scores with the words to create a dictionary\n",
    "                # and update the features dictionary with this new dictionary\n",
    "                if tfidf_scores.size > 0:\n",
    "                    word_scores = {f\"tf_idfs_{word}\": score for word, score in zip(all_words, tfidf_scores[0])}\n",
    "                    features.update(word_scores)\n",
    "                else:  # If the TF-IDF scores array is empty, assign 0 to each word's score\n",
    "                    word_scores = {f\"tf_idfs_{word}\": 0 for word in all_words}\n",
    "                    features.update(word_scores)\n",
    "\n",
    "                features['label'] = label\n",
    "\n",
    "                # Add the feature dictionary to the feature list\n",
    "                feature_list.append(features)\n",
    "\n",
    "                # Print progress\n",
    "                print(f\"Processed row {total_rows_processed + 1}\")\n",
    "                total_rows_processed += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {total_rows_processed + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            # Convert the list of dictionaries into a DataFrame\n",
    "            new_data = pd.DataFrame(feature_list).fillna(0)\n",
    "\n",
    "            # Append new data to saved data and save\n",
    "            saved_data = pd.concat([saved_data, new_data])\n",
    "            saved_data.to_csv(save_file, index=False)\n",
    "\n",
    "            # Clear the feature list for the next batch\n",
    "            feature_list.clear()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk: {e}\")\n",
    "            continue\n",
    "\n",
    "    return saved_data\n",
    "\n",
    "\n",
    "# prepare_data_for_regression(\"extracted_data/gpt-3.5-turbo_and_human_data.csv\")\n",
    "\n",
    "\n",
    "def prepare_single_text_for_regression(input_text, prompt):\n",
    "    \"\"\"\n",
    "    This function prepares a single text for regression analysis by extracting features.\n",
    "\n",
    "    Args:\n",
    "    input_text (str): The input text string.\n",
    "    prompt (str): The prompt string.\n",
    "\n",
    "    Returns:\n",
    "    features (dict): A dictionary where each key-value pair represents a feature and its value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the model and tokenizer\n",
    "    model, tokenizer = load_model()\n",
    "\n",
    "    # Combine top_words and synonyms into one list\n",
    "    all_words = ['said', 'like', 'im', 'get', 'told', 'dont', 'say', 'know', 'think', 'look', 'conclusion', 'summarise',\n",
    "                 'summarize', 'finale', 'overall', 'sum', 'end', 'summary', 'conclude']\n",
    "\n",
    "    # Create a TF-IDF vectorizer with the top 10 words as vocabulary\n",
    "    vectorizer = TfidfVectorizer(vocabulary=all_words)\n",
    "\n",
    "    # Initialize the features dictionary here\n",
    "    features = {}\n",
    "\n",
    "    # Count POS tags in the text\n",
    "    pos_counts, punctuation_counts, function_word_counts = count_pos_tags_and_special_elements(input_text)\n",
    "\n",
    "    # Calculate the Flesch Reading Ease and Flesch-Kincaid Grade Level\n",
    "    flesch_reading_ease, flesch_kincaid_grade_level = calculate_readability_scores(input_text)\n",
    "\n",
    "    # Calculate the average word length\n",
    "    avg_word_length = calculate_average_word_length([input_text])\n",
    "\n",
    "    # Calculate the average sentence length\n",
    "    avg_sentence_length = calculate_average_sentence_length([input_text])\n",
    "\n",
    "    # Calculate cosine similarity between the prompt and the text\n",
    "    prompt_text_cosine_similarity = calculate_cosine_similarity_for_prompt_and_text(prompt, input_text, model,\n",
    "                                                                                    tokenizer)\n",
    "\n",
    "    # Calculate cosine similarities for each sentence in the text\n",
    "    sentence_cosine_similarities = calculate_cosine_similarities_for_sentences_in_text(input_text, model, tokenizer)\n",
    "\n",
    "    avg_sentence_cosine_similarity = 0\n",
    "    if sentence_cosine_similarities:\n",
    "        avg_sentence_cosine_similarity = sum(sentence_cosine_similarities) / len(sentence_cosine_similarities)\n",
    "    else:\n",
    "        print(\"WARNING: No sentence cosine similarities calculated for text:\", input_text)\n",
    "\n",
    "    # Transform the text into TF-IDF scores\n",
    "    tfidf_scores = vectorizer.fit_transform([input_text]).toarray()\n",
    "\n",
    "    # Calculate the perplexity of the text and average sentence perplexity\n",
    "    text_encoded = tokenizer.encode(input_text, truncation=True, max_length=510)\n",
    "    text = tokenizer.decode(text_encoded)\n",
    "    text = text.replace('<s>', '').replace('</s>', '')\n",
    "    text_perplexity = calculate_perplexity(text, model, tokenizer)\n",
    "    sentence_perplexities = [calculate_perplexity(sentence.text, model, tokenizer) for sentence in nlp(text).sents]\n",
    "    sentence_perplexities = [p for p in sentence_perplexities if p is not None]\n",
    "    avg_sentence_perplexity = sum(sentence_perplexities) / len(sentence_perplexities) if sentence_perplexities else None\n",
    "\n",
    "    # Calculate the frequency of uppercase letters\n",
    "    uppercase_freq = sum(1 for char in input_text if char.isupper()) / len(input_text)\n",
    "\n",
    "    # Prepare a dictionary to append to the feature list\n",
    "    features.update({\n",
    "        'ADJ': pos_counts.get('ADJ', 0),\n",
    "        'ADV': pos_counts.get('ADV', 0),\n",
    "        'CONJ': pos_counts.get('CCONJ', 0),\n",
    "        'NOUN': pos_counts.get('NOUN', 0),\n",
    "        'NUM': pos_counts.get('NUM', 0),\n",
    "        'VERB': pos_counts.get('VERB', 0),\n",
    "        'COMMA': punctuation_counts.get(',', 0),\n",
    "        'FULLSTOP': punctuation_counts.get('.', 0),\n",
    "        'SPECIAL-': punctuation_counts.get('-', 0),\n",
    "        'FUNCTION-A': function_word_counts.get('a', 0),\n",
    "        'FUNCTION-IN': function_word_counts.get('in', 0),\n",
    "        'FUNCTION-OF': function_word_counts.get('of', 0),\n",
    "        'FUNCTION-THE': function_word_counts.get('the', 0),\n",
    "        'uppercase_freq': uppercase_freq,\n",
    "        'flesch_reading_ease': flesch_reading_ease,\n",
    "        'flesch_kincaid_grade_level': flesch_kincaid_grade_level,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'avg_sentence_length': avg_sentence_length,\n",
    "        'text_perplexity': text_perplexity,\n",
    "        'avg_sentence_perplexity': avg_sentence_perplexity,\n",
    "        'prompt_text_cosine_similarity': prompt_text_cosine_similarity,\n",
    "        'avg_sentence_cosine_similarity': avg_sentence_cosine_similarity,\n",
    "    })\n",
    "\n",
    "    # If the TF-IDF scores array is not empty, zip the scores with the words to create a dictionary\n",
    "    # and update the features dictionary with this new dictionary\n",
    "    if tfidf_scores.size > 0:\n",
    "        word_scores = {f\"tf_idfs_{word}\": score for word, score in zip(all_words, tfidf_scores[0])}\n",
    "        features.update(word_scores)\n",
    "    else:  # If the TF-IDF scores array is empty, assign 0 to each word's score\n",
    "        word_scores = {f\"tf_idfs_{word}\": 0 for word in all_words}\n",
    "        features.update(word_scores)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def test_prepare_single_text_for_regression():\n",
    "    # Set the max columns option to None to display all columns\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    # Load the DataFrame from the data_matrix file\n",
    "    data_matrix = pd.read_csv('data_matrix_gpt-3.5-turbo.csv')\n",
    "\n",
    "    # Load the DataFrame from the gpt_3.5-turbo_and_human_data file\n",
    "    gpt_data = pd.read_csv('extracted_data/gpt-3.5-turbo_and_human_data.csv')\n",
    "\n",
    "    # Randomly select a row index\n",
    "    row_index = random.randint(0, len(data_matrix) - 1)\n",
    "\n",
    "    # Get the corresponding row from the data_matrix\n",
    "    data_matrix_row = data_matrix.iloc[[row_index]]  # double square brackets to keep it a DataFrame\n",
    "\n",
    "    # Reset the index for data_matrix_row\n",
    "    data_matrix_row = data_matrix_row.reset_index(drop=True)\n",
    "\n",
    "    # Get the corresponding row from the gpt_data\n",
    "    gpt_data_row = gpt_data.iloc[row_index]\n",
    "\n",
    "    # Extract the prompt and text from the gpt_data_row\n",
    "    prompts_and_texts = extract_prompts_and_texts([gpt_data_row])\n",
    "    prompt, text = prompts_and_texts[0]\n",
    "\n",
    "    # Prepare the single text for regression\n",
    "    features_from_single_text = prepare_single_text_for_regression(text, prompt)\n",
    "\n",
    "    # Convert the features_from_single_text into a DataFrame row\n",
    "    features_from_single_text_row = pd.Series(features_from_single_text).to_frame().T\n",
    "\n",
    "    # Reset the index for features_from_single_text_row\n",
    "    features_from_single_text_row = features_from_single_text_row.reset_index(drop=True)\n",
    "\n",
    "    # Print both rows\n",
    "    print(\"Data Matrix Row:\\n\", data_matrix_row)\n",
    "    print(\"Features From Single Text Row:\\n\", features_from_single_text_row)\n",
    "\n",
    "    # Check if the rows are the same\n",
    "    if data_matrix_row.equals(features_from_single_text_row):\n",
    "        print(\"Rows are the same\")\n",
    "    else:\n",
    "        print(\"Rows are different\")\n",
    "        differences = data_matrix_row.compare(features_from_single_text_row)\n",
    "        print(\"Differences:\\n\", differences)\n",
    "\n",
    "    # Reset the display option\n",
    "    pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be352e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "264f0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aee2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "710c9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model_choice):\n",
    "    if model_choice == 'logreg':\n",
    "        clf = LogisticRegression()\n",
    "        param_grid = [\n",
    "            {'solver': ['newton-cg', 'lbfgs', 'sag'], 'penalty': ['l2'], 'C': np.logspace(-2, 2, 10), 'max_iter': [1000]},\n",
    "        ]\n",
    "    elif model_choice == 'svm':\n",
    "        clf = SVC()\n",
    "        param_grid = [\n",
    "            {'kernel': ['linear', 'rbf'], 'C': np.logspace(-2, 2, 10), 'gamma': ['scale', 'auto']}\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model_choice '{model_choice}'. Choose either 'logreg' or 'svm'.\")\n",
    "\n",
    "    n_iter_search = 10\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_grid, n_iter=n_iter_search, cv=3, verbose=0, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model_best = random_search.best_estimator_\n",
    "    return model_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34c0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8069c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       178\n",
      "           1       0.90      0.93      0.92       152\n",
      "\n",
      "    accuracy                           0.92       330\n",
      "   macro avg       0.92      0.92      0.92       330\n",
      "weighted avg       0.92      0.92      0.92       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    model = joblib.load(filename)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "X, y = load_and_process_data(\"data_matrix_gpt-3.5-turbo.csv\")\n",
    "X_train, X_test, y_train, y_test, scaler = split_and_scale_data(X, y)\n",
    "model_choice = \"logreg\"\n",
    "try:\n",
    "    model_best = load_model(f'model_best_{model_choice}.joblib')\n",
    "except:\n",
    "    model_best = train_model(X_train, y_train, model_choice)\n",
    "    save_model(model_best, f'model_best_{model_choice}.joblib')\n",
    "y_pred = make_predictions(model_best, X_test)\n",
    "evaluate_model(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
