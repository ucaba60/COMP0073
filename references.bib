@Misc{mitchell2023detectgpt,
  author        = {Eric Mitchell and Yoonho Lee and Alexander Khazatsky and Christopher D. Manning and Chelsea Finn},
  title         = {DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2301.11305},
  primaryclass  = {cs.CL},
}

@Misc{tang2023science,
  author        = {Ruixiang Tang and Yu-Neng Chuang and Xia Hu},
  title         = {The Science of Detecting LLM-Generated Texts},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.07205},
  primaryclass  = {cs.CL},
}

@Misc{manakul2023selfcheckgpt,
  author        = {Potsawee Manakul and Adian Liusie and Mark J. F. Gales},
  title         = {SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.08896},
  primaryclass  = {cs.CL},
}

@Misc{yang2023dnagpt,
  author        = {Xianjun Yang and Wei Cheng and Linda Petzold and William Yang Wang and Haifeng Chen},
  title         = {DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.17359},
  primaryclass  = {cs.CL},
}

@Misc{wu2023llmdet,
  author        = {Kangxi Wu and Liang Pang and Huawei Shen and Xueqi Cheng and Tat-Seng Chua},
  title         = {LLMDet: A Large Language Models Detection Tool},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.15004},
  primaryclass  = {cs.CL},
}

@Misc{shahriar2023lets,
  author        = {Sakib Shahriar and Kadhim Hayawi},
  title         = {Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2302.13817},
  primaryclass  = {cs.CL},
}

@Misc{huang2023language,
  author        = {Shaohan Huang and Li Dong and Wenhui Wang and Yaru Hao and Saksham Singhal and Shuming Ma and Tengchao Lv and Lei Cui and Owais Khan Mohammed and Barun Patra and Qiang Liu and Kriti Aggarwal and Zewen Chi and Johan Bjorck and Vishrav Chaudhary and Subhojit Som and Xia Song and Furu Wei},
  title         = {Language Is Not All You Need: Aligning Perception with Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2302.14045},
  primaryclass  = {cs.CL},
}

@Misc{touvron2023llama,
  author        = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  title         = {LLaMA: Open and Efficient Foundation Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2302.13971},
  primaryclass  = {cs.CL},
}

@Misc{openai2023gpt4,
  author        = {OpenAI},
  title         = {GPT-4 Technical Report},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.08774},
  primaryclass  = {cs.CL},
}

@Article{Ayyar_2021,
  author    = {Meghna P. Ayyar and Jenny Benois-Pineau and Akka Zemmari},
  journal   = {Journal of Electronic Imaging},
  title     = {Review of white box methods for explanations of convolutional neural networks in image classification tasks},
  year      = {2021},
  month     = {sep},
  number    = {05},
  volume    = {30},
  doi       = {10.1117/1.jei.30.5.050901},
  publisher = {{SPIE}-Intl Soc Optical Eng},
  url       = {https://doi.org/10.1117%2F1.jei.30.5.050901},
}

@Misc{sekhon2022whitebox,
  author        = {Arshdeep Sekhon and Yangfeng Ji and Matthew B. Dwyer and Yanjun Qi},
  title         = {White-box Testing of NLP models with Mask Neuron Coverage},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2205.05050},
  primaryclass  = {cs.CL},
}

@Misc{vasilatos2023howkgpt,
  author        = {Christoforos Vasilatos and Manaar Alam and Talal Rahwan and Yasir Zaki and Michail Maniatakos},
  title         = {HowkGPT: Investigating the Detection of ChatGPT-generated University Student Homework through Context-Aware Perplexity Analysis},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.18226},
  primaryclass  = {cs.CL},
}

@Misc{ma2023ai,
  author        = {Yongqiang Ma and Jiawei Liu and Fan Yi and Qikai Cheng and Yong Huang and Wei Lu and Xiaozhong Liu},
  title         = {AI vs. Human -- Differentiation Analysis of Scientific Content Generation},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2301.10416},
  primaryclass  = {cs.CL},
}

@Misc{verma2023ghostbuster,
  author        = {Vivek Verma and Eve Fleisig and Nicholas Tomlin and Dan Klein},
  title         = {Ghostbuster: Detecting Text Ghostwritten by Large Language Models},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2305.15047},
  primaryclass  = {cs.CL},
}

@Article{pos_tag,
  author  = {Zewdu, Alebachew and Yitagesu, Betselot},
  journal = {Journal of Big Data},
  title   = {Part of speech tagging: a systematic review of deep learning and machine learning approaches},
  year    = {2022},
  month   = {01},
  volume  = {9},
  doi     = {10.1186/s40537-022-00561-y},
}


@Misc{guo2023close,
  author        = {Biyang Guo and Xin Zhang and Ziyuan Wang and Minqi Jiang and Jinran Nie and Yuxuan Ding and Jianwei Yue and Yupeng Wu},
  title         = {How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2301.07597},
  primaryclass  = {cs.CL},
}

@Misc{budach2022effects,
  author        = {Lukas Budach and Moritz Feuerpfeil and Nina Ihde and Andrea Nathansen and Nele Noack and Hendrik Patzlaff and Felix Naumann and Hazar Harmouch},
  title         = {The Effects of Data Quality on Machine Learning Performance},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2207.14529},
  primaryclass  = {cs.DB},
}

@Misc{radford_language_2019,
  author    = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, D. and Amodei, Dario and Sutskever, Ilya},
  title     = {Language models are unsupervised multitask learners},
  year      = {2019},
  abstract  = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  added-at  = {2023-01-14T15:28:29.000+0100},
  biburl    = {https://www.bibsonomy.org/bibtex/272c31587e067e0041527dabb3a34cdb8/lepsky},
  interhash = {b926ece39c03cdf5499f6540cf63babd},
  intrahash = {72c31587e067e0041527dabb3a34cdb8},
  keywords  = {chatgpt kuenstliche_intelligenz},
  timestamp = {2023-01-14T15:33:48.000+0100},
  url       = {https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe},
  urldate   = {2023-01-06},
}

@Article{pile,
  author  = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},
  journal = {arXiv preprint arXiv:2101.00027},
  title   = {The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},
  year    = {2020},
}

@Unknown{katareval,
  author = {Katar, Oğuzhan and Ozkan, Dilek and GPT, and Yildirim, Özal and Acharya, U Rajendra},
  doi    = {10.13140/RG.2.2.11949.15844},
  month  = {12},
  title  = {Evaluation of GPT-3 AI language model in research paper writing},
  year   = {2022},
}

@InProceedings{dugan-etal-2020-roft,
  author    = {Dugan, Liam and Ippolito, Daphne and Kirubarajan, Arun and Callison-Burch, Chris},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  title     = {{R}o{FT}: A Tool for Evaluating Human Detection of Machine-Generated Text},
  year      = {2020},
  address   = {Online},
  month     = oct,
  pages     = {189--196},
  publisher = {Association for Computational Linguistics},
  abstract  = {In recent years, large neural networks for natural language generation (NLG) have made leaps and bounds in their ability to generate fluent text. However, the tasks of evaluating quality differences between NLG systems and understanding how humans perceive the generated text remain both crucial and difficult. In this system demonstration, we present Real or Fake Text (RoFT), a website that tackles both of these challenges by inviting users to try their hand at detecting machine-generated text in a variety of domains. We introduce a novel evaluation task based on detecting the boundary at which a text passage that starts off human-written transitions to being machine-generated. We show preliminary results of using RoFT to evaluate detection of machine-generated news articles.},
  doi       = {10.18653/v1/2020.emnlp-demos.25},
  url       = {https://aclanthology.org/2020.emnlp-demos.25},
}

@Misc{sadasivan2023aigenerated,
  author        = {Vinu Sankar Sadasivan and Aounon Kumar and Sriram Balasubramanian and Wenxiao Wang and Soheil Feizi},
  title         = {Can AI-Generated Text be Reliably Detected?},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2303.11156},
  primaryclass  = {cs.CL},
}

@InProceedings{kushnareva-etal-2021-artificial,
  author    = {Kushnareva, Laida and Cherniavskii, Daniil and Mikhailov, Vladislav and Artemova, Ekaterina and Barannikov, Serguei and Bernstein, Alexander and Piontkovskaya, Irina and Piontkovski, Dmitri and Burnaev, Evgeny},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Artificial Text Detection via Examining the Topology of Attention Maps},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {635--649},
  publisher = {Association for Computational Linguistics},
  abstract  = {The impressive capabilities of recent generative models to create texts that are challenging to distinguish from the human-written ones can be misused for generating fake news, product reviews, and even abusive content. Despite the prominent performance of existing methods for artificial text detection, they still lack interpretability and robustness towards unseen models. To this end, we propose three novel types of interpretable topological features for this task based on Topological Data Analysis (TDA) which is currently understudied in the field of NLP. We empirically show that the features derived from the BERT model outperform count- and neural-based baselines up to 10{\%} on three common datasets, and tend to be the most robust towards unseen GPT-style generation models as opposed to existing methods. The probing analysis of the features reveals their sensitivity to the surface and syntactic properties. The results demonstrate that TDA is a promising line with respect to NLP tasks, specifically the ones that incorporate surface and structural information.},
  doi       = {10.18653/v1/2021.emnlp-main.50},
  url       = {https://aclanthology.org/2021.emnlp-main.50},
}

@InProceedings{jin-etal-2019-pubmedqa,
  author    = {Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  title     = {{P}ub{M}ed{QA}: A Dataset for Biomedical Research Question Answering},
  year      = {2019},
  address   = {Hong Kong, China},
  month     = nov,
  pages     = {2567--2577},
  publisher = {Association for Computational Linguistics},
  abstract  = {We introduce PubMedQA, a novel biomedical question answering (QA) dataset collected from PubMed abstracts. The task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts. PubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances. Each PubMedQA instance is composed of (1) a question which is either an existing research article title or derived from one, (2) a context which is the corresponding abstract without its conclusion, (3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question, and (4) a yes/no/maybe answer which summarizes the conclusion. PubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their quantitative contents, is required to answer the questions. Our best performing model, multi-phase fine-tuning of BioBERT with long answer bag-of-word statistics as additional supervision, achieves 68.1{\%} accuracy, compared to single human performance of 78.0{\%} accuracy and majority-baseline of 55.2{\%} accuracy, leaving much room for improvement. PubMedQA is publicly available at https://pubmedqa.github.io.},
  doi       = {10.18653/v1/D19-1259},
  url       = {https://aclanthology.org/D19-1259},
}

@InProceedings{fan-etal-2018-hierarchical,
  author    = {Fan, Angela and Lewis, Mike and Dauphin, Yann},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {Hierarchical Neural Story Generation},
  year      = {2018},
  address   = {Melbourne, Australia},
  month     = jul,
  pages     = {889--898},
  publisher = {Association for Computational Linguistics},
  abstract  = {We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.},
  doi       = {10.18653/v1/P18-1082},
  url       = {https://aclanthology.org/P18-1082},
}

@InProceedings{narayan-etal-2018-dont,
  author    = {Narayan, Shashi and Cohen, Shay B. and Lapata, Mirella},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  title     = {Don{'}t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},
  year      = {2018},
  address   = {Brussels, Belgium},
  month     = oct # {-} # nov,
  pages     = {1797--1807},
  publisher = {Association for Computational Linguistics},
  abstract  = {We introduce {``}extreme summarization{''}, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question {``}What is the article about?{''}. We collect a real-world, large-scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC). We propose a novel abstractive model which is conditioned on the article{'}s topics and based entirely on convolutional neural networks. We demonstrate experimentally that this architecture captures long-range dependencies in a document and recognizes pertinent content, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans.},
  doi       = {10.18653/v1/D18-1206},
  url       = {https://aclanthology.org/D18-1206},
}

@Misc{mitrović2023chatgpt,
  author        = {Sandra Mitrović and Davide Andreoletti and Omran Ayoub},
  title         = {ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine Learning Model for Detecting Short ChatGPT-generated Text},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2301.13852},
  primaryclass  = {cs.CL},
}

@InProceedings{inproceedings,
  author = {Lavergne, Thomas and Urvoy, Tanguy and Yvon, François},
  title  = {Detecting Fake Content with Relative Entropy Scoring.},
  year   = {2008},
  month  = {01},
}

@Misc{gehrmann2019gltr,
  author        = {Sebastian Gehrmann and Hendrik Strobelt and Alexander M. Rush},
  title         = {GLTR: Statistical Detection and Visualization of Generated Text},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1906.04043},
  primaryclass  = {cs.CL},
}

@Misc{chakraborty2023possibilities,
  author        = {Souradip Chakraborty and Amrit Singh Bedi and Sicheng Zhu and Bang An and Dinesh Manocha and Furong Huang},
  title         = {On the Possibilities of AI-Generated Text Detection},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2304.04736},
  primaryclass  = {cs.CL},
}

@Article{ROSENFELD1996187,
  author   = {Ronald Rosenfeld},
  journal  = {Computer Speech & Language},
  title    = {A maximum entropy approach to adaptive statistical language modelling},
  year     = {1996},
  issn     = {0885-2308},
  number   = {3},
  pages    = {187-228},
  volume   = {10},
  abstract = {An adaptive statistical language model is described, which successfully integrates long distance linguistic information with other knowledge sources. Most existing statistical language models exploit only the immediate history of a text. To extract information from further back in the document's history, we propose and usetrigger pairsas the basic information bearing elements. This allows the model to adapt its expectations to the topic of discourse. Next, statistical evidence from multiple sources must be combined. Traditionally, linear interpolation and its variants have been used, but these are shown here to be seriously deficient. Instead, we apply the principle of Maximum Entropy (ME). Each information source gives rise to a set of constraints, to be imposed on the combined estimate. The intersection of these constraints is the set of probability functions which are consistent with all the information sources. The function with the highest entropy within that set is the ME solution. Given consistent statistical evidence, a unique ME solution is guaranteed to exist, and an iterative algorithm exists which is guaranteed to converge to it. The ME framework is extremely general: any phenomenon that can be described in terms of statistics of the text can be readily incorporated. An adaptive language model based on the ME approach was trained on theWall Street Journalcorpus, and showed a 32–39% perplexity reduction over the baseline. When interfaced to SPHINX-II, Carnegie Mellon's speech recognizer, it reduced its error rate by 10–14%. This thus illustrates the feasibility of incorporating many diverse knowledge sources in a single, unified statistical framework.},
  doi      = {https://doi.org/10.1006/csla.1996.0011},
  url      = {https://www.sciencedirect.com/science/article/pii/S088523089690011X},
}

@Misc{arora2016contrastive,
  author        = {Kushal Arora and Anand Rangarajan},
  title         = {Contrastive Entropy: A new evaluation metric for unnormalized language models},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1601.00248},
  primaryclass  = {cs.CL},
}

@Article{Jelinek1977PerplexityaMO,
  author  = {Frederick Jelinek and Robert L. Mercer and Lalit R. Bahl and Janet M. Baker},
  journal = {Journal of the Acoustical Society of America},
  title   = {Perplexity—a measure of the difficulty of speech recognition tasks},
  year    = {1977},
  volume  = {62},
}

@InProceedings{inproceedings,
  author = {Suleiman, Dima and Awajan, Arafat and Al-Madi, Nailah},
  title  = {Deep Learning Based Technique for Plagiarism Detection in Arabic Texts},
  year   = {2017},
  month  = {10},
  doi    = {10.1109/ICTCS.2017.42},
}

@Article{Mostafa2020ADL,
  author  = {Hambi El Mostafa and Faouzia Benabbou},
  journal = {IAES International Journal of Artificial Intelligence},
  title   = {A deep learning based technique for plagiarism detection: a comparative study},
  year    = {2020},
  pages   = {81-90},
  volume  = {9},
}

@Article{evaluationofdifferent_plag,
  author  = {Jambi, Kamal and Khan, Imtiaz and Siddiqui, Muazzam},
  journal = {Applied Sciences},
  title   = {Evaluation of Different Plagiarism Detection Methods: A Fuzzy MCDM Perspective},
  year    = {2022},
  month   = {04},
  pages   = {4580},
  volume  = {12},
  doi     = {10.3390/app12094580},
}

@InProceedings{Das2021ACS,
  author    = {Mamata Das and Selvakumar Kamalanathan and Pja Alphonse},
  booktitle = {International Conference on Computational Linguistics and Intelligent Systems},
  title     = {A Comparative Study on TF-IDF Feature Weighting Method and Its Analysis Using Unstructured Dataset},
  year      = {2021},
}

@Misc{das2018improved,
  author        = {Bijoyan Das and Sarit Chakraborty},
  title         = {An Improved Text Sentiment Classification Model Using TF-IDF and Next Word Negation},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1806.06407},
  primaryclass  = {cs.CL},
}

@Article{stehpen_tfidf,
  author  = {Stephen, Akuma and Lubem, Tyosar and Adom, Isaac},
  journal = {International Journal of Information Technology},
  title   = {Comparing Bag of Words and TF-IDF with different models for hate speech detection from live tweets},
  year    = {2022},
  month   = {09},
  volume  = {14},
  doi     = {10.1007/s41870-022-01096-4},
}

@Article{featurebased,
  author  = {Fröhling, Leon and Zubiaga, Arkaitz},
  journal = {PeerJ Computer Science},
  title   = {Feature-based detection of automated language models: tackling GPT-2, GPT-3 and Grover},
  year    = {2021},
  month   = {04},
  pages   = {e443},
  volume  = {7},
  doi     = {10.7717/peerj-cs.443},
}

@Article{languageofschooling,
  author  = {Schleppegrell, Mary},
  journal = {The Language of Schooling: A Functional Linguistics Perspective},
  title   = {The Language of Schooling: A Functional Linguistics Perspective},
  year    = {2004},
  month   = {04},
  doi     = {10.4324/9781410610317},
  isbn    = {9781410610317},
}

@Article{nagy2012words,
  author    = {Nagy, William and Townsend, Dianna},
  journal   = {Reading research quarterly},
  title     = {Words as tools: Learning academic vocabulary as language acquisition},
  year      = {2012},
  number    = {1},
  pages     = {91--108},
  volume    = {47},
  publisher = {Wiley Online Library},
}

@Article{10.1145/344599.344637,
  author     = {Redish, Janice},
  journal    = {ACM J. Comput. Doc.},
  title      = {Readability Formulas Have Even More Limitations than Klare Discusses},
  year       = {2000},
  issn       = {1527-6805},
  month      = {aug},
  number     = {3},
  pages      = {132–137},
  volume     = {24},
  abstract   = {A literature review reveals many technical weaknesses of readability formulas (when compared to direct usability testing with typical readers): they were developed for children s school books, not adult technical documentation;they ignore between-reader differences and the effects of content, layout, and retrieval aids on text usefulness; they emphasize countable features at the expense of more subtle contributors to text comprehension.},
  address    = {New York, NY, USA},
  doi        = {10.1145/344599.344637},
  issue_date = {Aug. 2000},
  keywords   = {reliability, usability testing, text comprehension},
  numpages   = {6},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/344599.344637},
}

@Misc{islam2023distinguishing,
  author        = {Niful Islam and Debopom Sutradhar and Humaira Noor and Jarin Tasnim Raya and Monowara Tabassum Maisha and Dewan Md Farid},
  title         = {Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2306.01761},
  primaryclass  = {cs.CL},
}

@Misc{buruk2023academic,
  author        = {Oğuz 'Oz' Buruk},
  title         = {Academic Writing with GPT-3.5: Reflections on Practices, Efficacy and Transparency},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2304.11079},
  primaryclass  = {cs.CL},
}

@Comment{jabref-meta: databaseType:bibtex;}
