{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install bitsandbytes-cuda111\n!pip install datasets\n!pip install accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-12T10:15:00.611506Z","iopub.execute_input":"2023-07-12T10:15:00.611927Z","iopub.status.idle":"2023-07-12T10:15:46.931688Z","shell.execute_reply.started":"2023-07-12T10:15:00.611895Z","shell.execute_reply":"2023-07-12T10:15:46.930424Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nCollecting bitsandbytes-cuda111\n  Downloading bitsandbytes_cuda111-0.26.0.post2-py3-none-any.whl (4.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes-cuda111\nSuccessfully installed bitsandbytes-cuda111-0.26.0.post2\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:15:46.934113Z","iopub.execute_input":"2023-07-12T10:15:46.934489Z","iopub.status.idle":"2023-07-12T10:16:02.389375Z","shell.execute_reply.started":"2023-07-12T10:15:46.934455Z","shell.execute_reply":"2023-07-12T10:16:02.388211Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.40.0.post4-py3-none-any.whl (101.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.40.0.post4\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.cuda.amp import custom_fwd, custom_bwd\nimport accelerate\nfrom bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:16:02.391259Z","iopub.execute_input":"2023-07-12T10:16:02.391653Z","iopub.status.idle":"2023-07-12T10:16:14.594356Z","shell.execute_reply.started":"2023-07-12T10:16:02.391616Z","shell.execute_reply":"2023-07-12T10:16:14.593391Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so\nCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 6.0\nCUDA SETUP: Detected CUDA version 118\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/nvidia/lib')}\n  warn(msg)\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n  warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"class FrozenBNBLinear(nn.Module):\n    def __init__(self, weight, absmax, code, bias=None):\n        assert isinstance(bias, nn.Parameter) or bias is None\n        super().__init__()\n        self.out_features, self.in_features = weight.shape\n        self.register_buffer(\"weight\", weight.requires_grad_(False))\n        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n        self.register_buffer(\"code\", code.requires_grad_(False))\n        self.adapter = None\n        self.bias = bias\n \n    def forward(self, input):\n        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n        if self.adapter:\n            output += self.adapter(input)\n        return output\n \n    @classmethod\n    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n        return cls(weights_int8, *state, linear.bias)\n \n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n \n \nclass DequantizeAndLinear(torch.autograd.Function): \n    @staticmethod\n    @custom_fwd\n    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n        ctx.save_for_backward(input, weights_quantized, absmax, code)\n        ctx._has_bias = bias is not None\n        return F.linear(input, weights_deq, bias)\n \n    @staticmethod\n    @custom_bwd\n    def backward(ctx, grad_output: torch.Tensor):\n        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n        input, weights_quantized, absmax, code = ctx.saved_tensors\n        # grad_output: [*batch, out_features]\n        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n        grad_input = grad_output @ weights_deq\n        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n        return grad_input, None, None, None, grad_bias\n \n \nclass FrozenBNBEmbedding(nn.Module):\n    def __init__(self, weight, absmax, code):\n        super().__init__()\n        self.num_embeddings, self.embedding_dim = weight.shape\n        self.register_buffer(\"weight\", weight.requires_grad_(False))\n        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n        self.register_buffer(\"code\", code.requires_grad_(False))\n        self.adapter = None\n \n    def forward(self, input, **kwargs):\n        with torch.no_grad():\n            # note: both quantuized weights and input indices are *not* differentiable\n            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n            output = F.embedding(input, weight_deq, **kwargs)\n        if self.adapter:\n            output += self.adapter(input)\n        return output \n \n    @classmethod\n    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n        return cls(weights_int8, *state)\n \n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n \n \ndef quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n    assert chunk_size % 4096 == 0\n    code = None\n    chunks = []\n    absmaxes = []\n    flat_tensor = matrix.view(-1)\n    for i in range((matrix.numel() - 1) // chunk_size + 1):\n        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n        chunks.append(quantized_chunk)\n        absmaxes.append(absmax_chunk)\n \n    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n    absmax = torch.cat(absmaxes)\n    return matrix_i8, (absmax, code)\n \n \ndef convert_to_int8(model):\n    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n    for module in list(model.modules()):\n        for name, child in module.named_children():\n            if isinstance(child, nn.Linear):\n                print(name, child)\n                setattr( \n                    module,\n                    name,\n                    FrozenBNBLinear(\n                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n                        code=torch.zeros(256),\n                        bias=child.bias,\n                    ),\n                )\n            elif isinstance(child, nn.Embedding):\n                setattr(\n                    module,\n                    name,\n                    FrozenBNBEmbedding(\n                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n                        code=torch.zeros(256),\n                    )\n                )","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:16:14.597387Z","iopub.execute_input":"2023-07-12T10:16:14.597958Z","iopub.status.idle":"2023-07-12T10:16:14.625022Z","shell.execute_reply.started":"2023-07-12T10:16:14.597920Z","shell.execute_reply":"2023-07-12T10:16:14.623702Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n    def __init__(self, config):\n        super().__init__(config)\n\n        convert_to_int8(self.attn)\n        convert_to_int8(self.mlp)\n\n\nclass GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n    def __init__(self, config):\n        super().__init__(config)\n        convert_to_int8(self)\n        \n\nclass GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n    def __init__(self, config):\n        super().__init__(config)\n        convert_to_int8(self)\n\n\ntransformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock  # monkey-patch GPT-J","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:16:14.627377Z","iopub.execute_input":"2023-07-12T10:16:14.628352Z","iopub.status.idle":"2023-07-12T10:16:15.119529Z","shell.execute_reply.started":"2023-07-12T10:16:14.628316Z","shell.execute_reply":"2023-07-12T10:16:15.118620Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:16:15.120735Z","iopub.execute_input":"2023-07-12T10:16:15.121059Z","iopub.status.idle":"2023-07-12T10:16:17.914854Z","shell.execute_reply.started":"2023-07-12T10:16:15.121028Z","shell.execute_reply":"2023-07-12T10:16:17.913772Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c31ba70fc6431bb7cba51acc0b9f77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73cc2b638b614d6891dd46e580de9609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a9ebbc4beb48f590839a990e4d382c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95d50763464542daaa67dd0e6d895702"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3446368e8c648bfb03561602654a64f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/4.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"457eb32376e84fe5a51cc4e277f32fe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"039d516a26af4d24bc687288f5c2531c"}},"metadata":{}}]},{"cell_type":"code","source":"import accelerate","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:16:17.916312Z","iopub.execute_input":"2023-07-12T10:16:17.916688Z","iopub.status.idle":"2023-07-12T10:16:17.921028Z","shell.execute_reply.started":"2023-07-12T10:16:17.916652Z","shell.execute_reply":"2023-07-12T10:16:17.919978Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"gpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ngpt.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:16:17.922508Z","iopub.execute_input":"2023-07-12T10:16:17.923114Z","iopub.status.idle":"2023-07-12T10:18:19.958497Z","shell.execute_reply.started":"2023-07-12T10:16:17.923076Z","shell.execute_reply":"2023-07-12T10:18:19.957452Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"507e2e0772d743e19917cc8a0bd11d8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc4646a4706148bea15d92842f8a425e"}},"metadata":{}},{"name":"stdout","text":"k_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nlm_head Linear(in_features=4096, out_features=50400, bias=True)\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"GPTJForCausalLM(\n  (transformer): GPTJModel(\n    (wte): FrozenBNBEmbedding(50400, 4096)\n    (drop): Dropout(p=0.0, inplace=False)\n    (h): ModuleList(\n      (0-27): 28 x GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): FrozenBNBLinear(4096, 50400)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:18:19.963594Z","iopub.execute_input":"2023-07-12T10:18:19.964248Z","iopub.status.idle":"2023-07-12T10:18:19.969654Z","shell.execute_reply.started":"2023-07-12T10:18:19.964208Z","shell.execute_reply":"2023-07-12T10:18:19.967434Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Load the prompts\ndf = pd.read_csv(\"/kaggle/input/prompts/prompts_pubmed.csv\")\nprompts = df['Prompt'].tolist()\n\n# Construct the response file path\nresponse_csv_path = os.path.join(\"/kaggle/working/\",\"gpt-j1x_responses.csv\")\n\n# Check if the response file already exists\nif os.path.exists(response_csv_path):\n    # Load the existing responses\n    existing_responses_df = pd.read_csv(response_csv_path)\n\n    # Determine the starting point based on the number of existing responses\n    start = len(existing_responses_df)\nelse:\n    start = 0\n\nfor i in range(start, len(prompts)):\n    # Encode the prompt\n    input_ids = tokenizer.encode(prompts[i], return_tensors=\"pt\").to(device)\n\n    # Generate a response\n    output = gpt.generate(\n            input_ids,\n            attention_mask=torch.ones_like(input_ids),  # Set all positions to 1 (i.e., no padding)\n            pad_token_id=tokenizer.eos_token_id,  # Use the EOS token as the PAD token\n            do_sample=True,\n            max_length=1024, \n        )\n\n    # Calculate the number of tokens in the prompt\n    prompt_length = input_ids.shape[-1]\n\n    # Decode only the response, excluding the prompt\n    response = tokenizer.decode(output[0, prompt_length:], skip_special_tokens=True)\n\n    # Save the prompt and response to a DataFrame\n    response_df = pd.DataFrame({\n        'Prompt': [prompts[i]],\n        'Response': [response]\n    })\n\n    # Append the DataFrame to the CSV file\n    if os.path.exists(response_csv_path):\n        response_df.to_csv(response_csv_path, mode='a', header=False, index=False)\n    else:\n        response_df.to_csv(response_csv_path, mode='w', index=False)\n\n    print(f\"Prompt {i + 1} of {len(prompts)} processed\")\n\nprint(f\"All prompts processed. Responses saved to {response_csv_path}.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:48:48.639817Z","iopub.execute_input":"2023-07-12T04:48:48.640875Z","iopub.status.idle":"2023-07-12T08:34:08.268925Z","shell.execute_reply.started":"2023-07-12T04:48:48.640832Z","shell.execute_reply":"2023-07-12T08:34:08.267933Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Prompt 207 of 300 processed\nPrompt 208 of 300 processed\nPrompt 209 of 300 processed\nPrompt 210 of 300 processed\nPrompt 211 of 300 processed\nPrompt 212 of 300 processed\nPrompt 213 of 300 processed\nPrompt 214 of 300 processed\nPrompt 215 of 300 processed\nPrompt 216 of 300 processed\nPrompt 217 of 300 processed\nPrompt 218 of 300 processed\nPrompt 219 of 300 processed\nPrompt 220 of 300 processed\nPrompt 221 of 300 processed\nPrompt 222 of 300 processed\nPrompt 223 of 300 processed\nPrompt 224 of 300 processed\nPrompt 225 of 300 processed\nPrompt 226 of 300 processed\nPrompt 227 of 300 processed\nPrompt 228 of 300 processed\nPrompt 229 of 300 processed\nPrompt 230 of 300 processed\nPrompt 231 of 300 processed\nPrompt 232 of 300 processed\nPrompt 233 of 300 processed\nPrompt 234 of 300 processed\nPrompt 235 of 300 processed\nPrompt 236 of 300 processed\nPrompt 237 of 300 processed\nPrompt 238 of 300 processed\nPrompt 239 of 300 processed\nPrompt 240 of 300 processed\nPrompt 241 of 300 processed\nPrompt 242 of 300 processed\nPrompt 243 of 300 processed\nPrompt 244 of 300 processed\nPrompt 245 of 300 processed\nPrompt 246 of 300 processed\nPrompt 247 of 300 processed\nPrompt 248 of 300 processed\nPrompt 249 of 300 processed\nPrompt 250 of 300 processed\nPrompt 251 of 300 processed\nPrompt 252 of 300 processed\nPrompt 253 of 300 processed\nPrompt 254 of 300 processed\nPrompt 255 of 300 processed\nPrompt 256 of 300 processed\nPrompt 257 of 300 processed\nPrompt 258 of 300 processed\nPrompt 259 of 300 processed\nPrompt 260 of 300 processed\nPrompt 261 of 300 processed\nPrompt 262 of 300 processed\nPrompt 263 of 300 processed\nPrompt 264 of 300 processed\nPrompt 265 of 300 processed\nPrompt 266 of 300 processed\nPrompt 267 of 300 processed\nPrompt 268 of 300 processed\nPrompt 269 of 300 processed\nPrompt 270 of 300 processed\nPrompt 271 of 300 processed\nPrompt 272 of 300 processed\nPrompt 273 of 300 processed\nPrompt 274 of 300 processed\nPrompt 275 of 300 processed\nPrompt 276 of 300 processed\nPrompt 277 of 300 processed\nPrompt 278 of 300 processed\nPrompt 279 of 300 processed\nPrompt 280 of 300 processed\nPrompt 281 of 300 processed\nPrompt 282 of 300 processed\nPrompt 283 of 300 processed\nPrompt 284 of 300 processed\nPrompt 285 of 300 processed\nPrompt 286 of 300 processed\nPrompt 287 of 300 processed\nPrompt 288 of 300 processed\nPrompt 289 of 300 processed\nPrompt 290 of 300 processed\nPrompt 291 of 300 processed\nPrompt 292 of 300 processed\nPrompt 293 of 300 processed\nPrompt 294 of 300 processed\nPrompt 295 of 300 processed\nPrompt 296 of 300 processed\nPrompt 297 of 300 processed\nPrompt 298 of 300 processed\nPrompt 299 of 300 processed\nPrompt 300 of 300 processed\nAll prompts processed. Responses saved to /kaggle/working/gpt-j1x_responses.csv.\n","output_type":"stream"}]},{"cell_type":"code","source":"response_csv_path = \"/kaggle/input/responses-to-fix/gpt-j1x_responses.csv\"\n# Load the responses\ndf = pd.read_csv(response_csv_path)\nresponse_csv_path = os.path.join(\"/kaggle/working/\",\"gpt-j1x_responses_fix2.csv\")\nprompts = df['Prompt'].tolist()\n\n# Iterate over the DataFrame\nfor i, row in df.iterrows():\n    if pd.isnull(row['Response']):\n        # Encode the prompt\n        input_ids = tokenizer.encode(row['Prompt'], return_tensors=\"pt\").to(device)\n\n        # Generate a response\n        # Generate a response\n        output = gpt.generate(\n                input_ids,\n                attention_mask=torch.ones_like(input_ids),  # Set all positions to 1 (i.e., no padding)\n                pad_token_id=tokenizer.eos_token_id,  # Use the EOS token as the PAD token\n                do_sample=True,\n                max_length=1024, \n            )\n\n        # Calculate the number of tokens in the prompt\n        prompt_length = input_ids.shape[-1]\n\n        # Decode only the response, excluding the prompt\n        response = tokenizer.decode(output[0, prompt_length:], skip_special_tokens=True)\n\n        # Replace the NaN response with the new one\n        df.at[i, 'Response'] = response\n        \n        response_df = pd.DataFrame({\n        'Prompt': [prompts[i]],\n        'Response': [response]\n            })\n\n              # Append the DataFrame to the CSV file\n        if os.path.exists(response_csv_path):\n            response_df.to_csv(response_csv_path, mode='a', header=False, index=False)\n        else:\n            response_df.to_csv(response_csv_path, mode='w', index=False)\n\n        print(\n            f\"Regenerated response for prompt {i + 1} of {len(df)}. Updated responses saved to {response_csv_path}.\")\n\nprint(f\"All NaN responses regenerated. Updated responses saved to {response_csv_path}.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T10:18:19.973735Z","iopub.execute_input":"2023-07-12T10:18:19.974008Z","iopub.status.idle":"2023-07-12T10:25:05.818927Z","shell.execute_reply.started":"2023-07-12T10:18:19.973983Z","shell.execute_reply":"2023-07-12T10:25:05.817793Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Regenerated response for prompt 451 of 825. Updated responses saved to /kaggle/working/gpt-j1x_responses_fix2.csv.\nRegenerated response for prompt 475 of 825. Updated responses saved to /kaggle/working/gpt-j1x_responses_fix2.csv.\nRegenerated response for prompt 523 of 825. Updated responses saved to /kaggle/working/gpt-j1x_responses_fix2.csv.\nRegenerated response for prompt 649 of 825. Updated responses saved to /kaggle/working/gpt-j1x_responses_fix2.csv.\nRegenerated response for prompt 818 of 825. Updated responses saved to /kaggle/working/gpt-j1x_responses_fix2.csv.\nAll NaN responses regenerated. Updated responses saved to /kaggle/working/gpt-j1x_responses_fix2.csv.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}